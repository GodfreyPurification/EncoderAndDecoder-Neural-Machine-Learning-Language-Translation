{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce806ce6-70ce-4fa7-9421-f6a43e76eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=f-JCCOHwx1c&list=PLZoTAELRMXVPGU70ZGsckrMdr0FteeRUi&index=52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee40a50-5c5a-40a5-8e70-e8b6d1ae1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "batch_size=64 \n",
    "epochs=100 \n",
    "latent_dim=256\n",
    "num_samples=10000\n",
    "data_path= '../sourcefile/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028c5a9-af08-4eb9-9254-24667ca1165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vectorize the data\n",
    "## input and counting character\n",
    "input_texts= [] \n",
    "target_texts= []\n",
    "input_charaters = set()\n",
    "target_charaters = set() \n",
    "with open(data_path,'r', encoding='utf-8') as f: \n",
    "    lines=f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines)-1)]: \n",
    "    input_text, target_text, _=line.split('\\t')\n",
    "    target_text='\\t'+ target_text+'\\n' \n",
    "    input_texts.append(input_text) \n",
    "    target_texts.append(target_text) \n",
    "    for char in input_text: \n",
    "        if char not in input_charaters: \n",
    "            input_charaters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_charaters:\n",
    "            target_charaters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21368e24-5e0a-40d4-9cce-dd9c85b113b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_charaters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf18560-360a-46d1-9624-8f72178c87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_charaters=sorted(list(input_charaters)) \n",
    "target_charaters=sorted(list(target_charaters)) \n",
    "num_encoder_tokens=len(input_charaters) \n",
    "num_decoder_tokens=len(target_charaters)\n",
    "max_encoder_seq_length=max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length=max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0233d741-8c29-4b78-9251-b2d4f3d2914f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sample : 10000\n",
      "Number of Unique input Token 70\n",
      "Number of Unique output Token 91\n",
      "Max sequence length for inputs: 14\n",
      "Max sequence length for output: 59\n"
     ]
    }
   ],
   "source": [
    "print('Number of sample :', len(input_texts))\n",
    "print('Number of Unique input Token', num_encoder_tokens)\n",
    "print('Number of Unique output Token', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length) \n",
    "print('Max sequence length for output:', max_decoder_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b95438e-8870-4a91-9137-d75dc8dd1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index=dict( \n",
    "    [(char, i) for i, char in enumerate(input_charaters)])\n",
    "target_token_index= dict( \n",
    "    [(char, i) for i, char in enumerate(target_charaters)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "172c4a0c-c722-494b-92f8-233da532425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data=np.zeros( \n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), \n",
    "    dtype='float32')\n",
    "decoder_input_data=np.zeros( \n",
    "    (len(input_texts), max_decoder_seq_length,num_decoder_tokens), \n",
    "    dtype='float32') \n",
    "decoder_target_data=np.zeros( \n",
    "    (len(input_texts), max_decoder_seq_length,num_decoder_tokens), \n",
    "    dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c893f9b-1e44-4016-b00f-3501751c01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts,target_texts)): \n",
    "    for t, char in enumerate(input_text): \n",
    "        encoder_input_data[i,t,input_token_index[char]]=1.\n",
    "    encoder_input_data[i,t+1:, input_token_index[' ']]=1. \n",
    "    for t, char in enumerate(target_text): \n",
    "        decoder_input_data[i,t, target_token_index[char]]=1. \n",
    "        if t> 0: \n",
    "            decoder_input_data[i,t-1:, target_token_index[char]]=1.\n",
    "    decoder_input_data[i,t+1:, target_token_index[' ']] =1.\n",
    "    decoder_target_data[i,t:, target_token_index[' ']]=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7293d8-c60c-4b1b-a710-1f686707e7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 70)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44dd08f2-24b8-49ee-8f4b-f7c9650f4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inpts=Input(shape=(None,num_decoder_tokens)) the line has been fixed \n",
    "# https://gemini.google.com/app/e874598beb5a709a  solution link\n",
    "#https://keras.io/examples/nlp/lstm_seq2seq/ blog soluton link\n",
    "encoder_inpts = Input(shape=(None, num_encoder_tokens))\n",
    "encoder=LSTM(latent_dim, return_state=True) \n",
    "encoder_outputs, state_h, state_c=encoder(encoder_inpts) \n",
    "encoder_states=[state_h,state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e95a9bd-d353-4b86-86ad-bc031aad85fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define an input sequences and process  \n",
    "decoder_inputs=Input(shape=(None,num_decoder_tokens)) \n",
    "decoder_lstm=LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,_,_= decoder_lstm(decoder_inputs, initial_state=encoder_states) \n",
    "decoder_dense=Dense(num_decoder_tokens, activation='softmax') \n",
    "decoder_outputs=decoder_dense(decoder_outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02363ea-df60-4f1f-8c46-a4c6b6500ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 424ms/step - accuracy: 0.6737 - loss: 0.2705 - val_accuracy: 0.6649 - val_loss: 0.0258\n",
      "Epoch 2/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 365ms/step - accuracy: 0.7029 - loss: 0.0557 - val_accuracy: 0.6649 - val_loss: 0.0259\n",
      "Epoch 3/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 411ms/step - accuracy: 0.7016 - loss: 0.0563 - val_accuracy: 0.6649 - val_loss: 0.0277\n",
      "Epoch 4/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 362ms/step - accuracy: 0.7024 - loss: 0.0504 - val_accuracy: 0.6649 - val_loss: 0.0369\n",
      "Epoch 5/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 461ms/step - accuracy: 0.7015 - loss: 0.0442 - val_accuracy: 0.6649 - val_loss: 0.0432\n",
      "Epoch 6/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 418ms/step - accuracy: 0.7041 - loss: 0.0404 - val_accuracy: 0.6649 - val_loss: 0.0249\n",
      "Epoch 7/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 449ms/step - accuracy: 0.7040 - loss: 0.0314 - val_accuracy: 0.6649 - val_loss: 0.0240\n",
      "Epoch 8/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 456ms/step - accuracy: 0.7024 - loss: 0.0308 - val_accuracy: 0.6649 - val_loss: 0.0492\n",
      "Epoch 9/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 525ms/step - accuracy: 0.7030 - loss: 0.0304 - val_accuracy: 0.6649 - val_loss: 0.0307\n",
      "Epoch 10/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 535ms/step - accuracy: 0.7020 - loss: 0.0287 - val_accuracy: 0.6649 - val_loss: 0.0238\n",
      "Epoch 11/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 576ms/step - accuracy: 0.7031 - loss: 0.0282 - val_accuracy: 0.6649 - val_loss: 0.0181\n",
      "Epoch 12/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 390ms/step - accuracy: 0.7034 - loss: 0.0278 - val_accuracy: 0.6649 - val_loss: 0.0340\n",
      "Epoch 13/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 337ms/step - accuracy: 0.7030 - loss: 0.0277 - val_accuracy: 0.6649 - val_loss: 0.0305\n",
      "Epoch 14/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 458ms/step - accuracy: 0.7021 - loss: 0.0271 - val_accuracy: 0.6649 - val_loss: 0.0289\n",
      "Epoch 15/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 352ms/step - accuracy: 0.7019 - loss: 0.0263 - val_accuracy: 0.6649 - val_loss: 0.0269\n",
      "Epoch 16/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 352ms/step - accuracy: 0.7031 - loss: 0.0261 - val_accuracy: 0.6649 - val_loss: 0.0214\n",
      "Epoch 17/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 400ms/step - accuracy: 0.7018 - loss: 0.0257 - val_accuracy: 0.6649 - val_loss: 0.0187\n",
      "Epoch 18/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 347ms/step - accuracy: 0.7018 - loss: 0.0253 - val_accuracy: 0.6649 - val_loss: 0.0200\n",
      "Epoch 19/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 416ms/step - accuracy: 0.7010 - loss: 0.0253 - val_accuracy: 0.6649 - val_loss: 0.0170\n",
      "Epoch 20/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 454ms/step - accuracy: 0.7014 - loss: 0.0253 - val_accuracy: 0.6649 - val_loss: 0.0181\n",
      "Epoch 21/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 410ms/step - accuracy: 0.7023 - loss: 0.0253 - val_accuracy: 0.6649 - val_loss: 0.0296\n",
      "Epoch 22/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 400ms/step - accuracy: 0.7027 - loss: 0.0246 - val_accuracy: 0.6649 - val_loss: 0.0313\n",
      "Epoch 23/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 855ms/step - accuracy: 0.7010 - loss: 0.0248 - val_accuracy: 0.6649 - val_loss: 0.0312\n",
      "Epoch 24/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.7017 - loss: 0.0252 - val_accuracy: 0.6649 - val_loss: 0.0164\n",
      "Epoch 25/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 799ms/step - accuracy: 0.7022 - loss: 0.0250 - val_accuracy: 0.6649 - val_loss: 0.0213\n",
      "Epoch 26/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 631ms/step - accuracy: 0.7025 - loss: 0.0246 - val_accuracy: 0.6649 - val_loss: 0.0357\n",
      "Epoch 27/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 496ms/step - accuracy: 0.7017 - loss: 0.0249 - val_accuracy: 0.6649 - val_loss: 0.0381\n",
      "Epoch 28/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 642ms/step - accuracy: 0.7017 - loss: 0.0250 - val_accuracy: 0.6649 - val_loss: 0.0152\n",
      "Epoch 29/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 556ms/step - accuracy: 0.7047 - loss: 0.0243 - val_accuracy: 0.6649 - val_loss: 0.0191\n",
      "Epoch 30/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 549ms/step - accuracy: 0.7026 - loss: 0.0231 - val_accuracy: 0.6649 - val_loss: 0.0162\n",
      "Epoch 31/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 991ms/step - accuracy: 0.7021 - loss: 0.0235 - val_accuracy: 0.6649 - val_loss: 0.0237\n",
      "Epoch 32/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 831ms/step - accuracy: 0.7022 - loss: 0.0233 - val_accuracy: 0.6649 - val_loss: 0.0137\n",
      "Epoch 33/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 566ms/step - accuracy: 0.7022 - loss: 0.0230 - val_accuracy: 0.6649 - val_loss: 0.0272\n",
      "Epoch 34/100\n",
      "\u001b[1m 77/125\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 792ms/step - accuracy: 0.7009 - loss: 0.0227"
     ]
    }
   ],
   "source": [
    "# model=Model([encoder_inpts,decoder_inputs], decoder_outputs)\n",
    "# model.compile(optimizer='rmsprop', loss='categorocal_crossentropy', \n",
    "#               metrics=['accuracy']) \n",
    "# model.fit=([encoder_input_data,decoder_input_data], decoder_target_data, \n",
    "#             batch_size=64, epochs=10, validation_split=0.2)\n",
    "\n",
    "\n",
    "model = Model([encoder_inpts, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d896d-56ff-42e6-8cb7-c3072539159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=f-JCCOHwx1c&list=PLZoTAELRMXVPGU70ZGsckrMdr0FteeRUi&index=52"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_flask3.11",
   "language": "python",
   "name": "env_flask3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
